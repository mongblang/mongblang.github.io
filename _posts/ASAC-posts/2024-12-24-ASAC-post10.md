# CURL(client url)
> 외국회사 api 등에서 나타나는 방식으로, 접속 관ㄹ녀된 부분에 대해 다 명령어/코드로 작성해야 함  
- 
curlconverter: curl방식으로 샘플이 주어진 사이트의 curl명령어를 파이썬으로 변환

---

## Pandas로 외부 데이터 주고받기
1. 웹 데이터: json, xml, html etc
2. 파일로 주고 받을 때: R, SAS, SPSS, 엑셀, 서버 etc 

    ``` python
    pd.read_데이터타입 # pandas에서 파일 불러오기
    df.to_데이터타입 # 데이터프레임을 파일로 저장
    ``` 

### 파일 양식
- 파일
    - csv: 데이터를 주고받을 때 주로 활용하는 파일 양식으로, 전달하고자 하는 값, 값들을 구분하는 구분자가(, . tab @ 등) 존재 
        - input: `pd.read_csv("파일명.csv", 파라미터)` output: `df.to_csv("파일명.csv", 파라미터)`
        - 파라미터: sep=, header=T/F/None, skiprows=n 등  
    - xls/xlsx: 2차원의 시트가 여러개 모인 3차원 자료형으로, 일반적 사용성은 높지만 값+서식이 있어서 파일이 무거움
        - input: `pd.read_excel("파일명", 파라미터)` output: `df.to_excel("파일명.xls/xlsx", 파라미터)`
        - 어떤 시트를 불러올지 지정 필요 !
    
- 웹/ 서로 다른 os/sw
    - json
    - xml 
- 서버
    - mysql
    - MsSQL 

---

## DF 병합 
1. 이어붙여서 연결 - concat 
    - 형식: `pd.concat([합칠 대상1, 대상2, ...], axis=0/1, ...)`
        - `axis = 0/1` : 0은 행 기준 (기본값) - 아래로 붙음, 1은 열 기준 - 옆으로 붙음
        - `ignore_index=T/F`: 데이터를 합치면서 인덱스가 중복되거나 꼬일 때 기존의 가로줄 인덱스를 무시하고 인덱스를 초기화 (지정한 축에 대해 적용됨)

        > 인덱스를 통일하지 않으면 이상하게 합쳐질 수 있으니 주의! 

    ### 인덱스 관련 파라미터/메서드드
    - ignore_index = T/F
    - reset_index()
    - reindex(기준이 될 DF)
2. 특정 조건에 맞춰서 연결 (sql의 join과 유사) - merge
    - 형식: `pd.merge(왼쪽에 둘 Df, 오른쪽에 둘 DF, how="조인방식", 기준=left/right_on)`
        - `how= "left", "right", "inner"`
        - `left_on=`왼쪽에 있는 DF의 기준 컬럼/인덱스(들)
        - `right_on=`오른쪽에 있는 DF의 기준 컬럼/인덱스(들)
        - `on =` 공통으로 있는 기준 컬럼/인덱스(들) 
        > 1:1, 1:n, n:m 연결 여부에 따라 합쳐진 데이터의 수가 달라질 수 있으니 주의! 
    - 기존에 사용하는 sql를 가지고 df에 적용하는 기능도 있음

    ```python
    # 1. left join - 좌측 df를 기준으로 조인 
    pd.merge(baseball_player, baseball_team, how="left", left_on="team_no", right_on="team_id")
    # 2. right join - 우측 df를 기준으로 조인 
    pd.merge(baseball_player, baseball_team, how = "right",left_on="team_no", right_on="team_id" ) 
    # 3. innter join - 교집합, 왼,오 df의 공통된 값을 기준으로 조인
    pd.merge(baseball_player, baseball_team, how="inner", left_on="team_no", right_on="team_id") 
    # 4. right exclusive join - 우측 df를 기준으로 조인하고 좌측 df의 누락값을 검색
    a = pd.merge(baseball_player, baseball_team, how="right", left_on="team_no", right_on="team_id")
        a[a.loc[:,"team_no"].isnull()]
    ```

---

# 1. Pandas 결측치 
## 1-1.유형
> Pandas에서 결측치로 인정한 경우에 대해서면 아래의 결측치 표기를 통해 표시함
1. Nan
2. None

## 결측치 처리

### 제거
- `dropna()`: 결측치 데이터를 삭제, 경우에 따라 샘플이 많이 삭제될 수 있음 
    - `axis 0/1`: 0은 행 기준, 1은 열 기준으로 결측치를 삭제
    - `how = "all"`: 완전히 누락된 데이터만 삭제 
    - `thresh=n`: axis 값을 기준으로 정상적인 값이 n개 이상일 시 삭제하지 않음 
    - 

### 대체
> 분석자가 주관적으로 수행하는 것으로, 대체할 값에 대한 정답은 없음 

- `fillna()`: 특정 값 등으로 결측치 대체
    - 평균, 중위수, 최빈값
    - 유사한 데이터를 보고 추정을 통해 대체 
    - 존재하는 값들을 대상으로 모델을 만들어 예측

```python
data.fillna(mean) # 평균값으로 결측치 대체 
data.fillna({0:0, 1:99}) # 컬럼별로 결측치 대체
``` 

---

# 피벗테이블 
> 수집된 데이터를 원하는 항목/속성/기준으로 확인하고자 하는 것 

- 형식: `pd.pivot_table(데이터, index=[가로값], values=[세로값])`
    > 값을 채우는 방식을 지정하지 않면 평균으로 채움 

- 파라미터:
    - columns=["컬럼명"]: value를 항복별로 쪼개서 세부적인 내용 확인 
    - aggfunc["집계함수"]: 값에 대한 집계 방법
    - fill_value=값: 결측값을 채움 
    - margins = T/F : True시 부분합(총계)을 계산 

## group by 와 차이점
> 기능적으로는 같음 

- pivot_table: 엑셀사용자를 위한 기능
- groupby: sql 사용자를 위한 기능