---
title: "Python 판다스 "
date: 2024-12-24
categories: [ASAC]
tags: [데이터분석, python]
layout: post
author: mongblang
---

# CURL(client url)
> 외국회사 api 등에서 나타나는 방식으로, 접속 관련된 부분에 대해 다 명령어/코드로 작성해야 함  
curlconverter: curl방식으로 샘플이 주어진 사이트의 curl명령어를 파이썬으로 변환

---

## Pandas로 외부 데이터 주고받기
1. 웹 데이터: json, xml, html etc
2. 파일로 주고 받을 때: R, SAS, SPSS, 엑셀, 서버 etc 

    ``` python
    pd.read_데이터타입 # pandas에서 파일 불러오기
    df.to_데이터타입 # 데이터프레임을 파일로 저장
    ``` 

### 파일 양식
- 파일
    - csv: 데이터를 주고받을 때 주로 활용하는 파일 양식으로, 전달하고자 하는 값, 값들을 구분하는 구분자가(, . tab @ 등) 존재 
        - input: `pd.read_csv("파일명.csv", 파라미터)` output: `df.to_csv("파일명.csv", 파라미터)`
        - 파라미터: sep=, header=T/F/None, skiprows=n 등  
    - xls/xlsx: 2차원의 시트가 여러개 모인 3차원 자료형으로, 일반적 사용성은 높지만 값+서식이 있어서 파일이 무거움
        - input: `pd.read_excel("파일명", 파라미터)` output: `df.to_excel("파일명.xls/xlsx", 파라미터)`
        - 어떤 시트를 불러올지 지정 필요 !
    
- 웹/ 서로 다른 os/sw
    - json
    - xml 
- 서버
    - mysql
    - MsSQL 

---

## DF 병합 
1. 이어붙여서 연결 - concat 
    - 형식: `pd.concat([합칠 대상1, 대상2, ...], axis=0/1, ...)`
        - `axis = 0/1` : 0은 행 기준 (기본값) - 아래로 붙음, 1은 열 기준 - 옆으로 붙음
        - `ignore_index=T/F`: 데이터를 합치면서 인덱스가 중복되거나 꼬일 때 기존의 가로줄 인덱스를 무시하고 인덱스를 초기화 (지정한 축에 대해 적용됨)

        > 인덱스를 통일하지 않으면 이상하게 합쳐질 수 있으니 주의! 

    ### 인덱스 관련 파라미터/메서드드
    - ignore_index = T/F
    - reset_index()
    - reindex(기준이 될 DF)
2. 특정 조건에 맞춰서 연결 (sql의 join과 유사) - merge
    - 형식: `pd.merge(왼쪽에 둘 Df, 오른쪽에 둘 DF, how="조인방식", 기준=left/right_on)`
        - `how= "left", "right", "inner"`
        - `left_on=`왼쪽에 있는 DF의 기준 컬럼/인덱스(들)
        - `right_on=`오른쪽에 있는 DF의 기준 컬럼/인덱스(들)
        - `on =` 공통으로 있는 기준 컬럼/인덱스(들) 
        > 1:1, 1:n, n:m 연결 여부에 따라 합쳐진 데이터의 수가 달라질 수 있으니 주의! 
    - 기존에 사용하는 sql를 가지고 df에 적용하는 기능도 있음

    ```python
    # 1. left join - 좌측 df를 기준으로 조인 
    pd.merge(baseball_player, baseball_team, how="left", left_on="team_no", right_on="team_id")
    # 2. right join - 우측 df를 기준으로 조인 
    pd.merge(baseball_player, baseball_team, how = "right",left_on="team_no", right_on="team_id" ) 
    # 3. innter join - 교집합, 왼,오 df의 공통된 값을 기준으로 조인
    pd.merge(baseball_player, baseball_team, how="inner", left_on="team_no", right_on="team_id") 
    # 4. right exclusive join - 우측 df를 기준으로 조인하고 좌측 df의 누락값을 검색
    a = pd.merge(baseball_player, baseball_team, how="right", left_on="team_no", right_on="team_id")
        a[a.loc[:,"team_no"].isnull()]
    ```

---

# 1. Pandas 결측치 
## 1-1.유형
> Pandas에서 결측치로 인정한 경우에 대해서면 아래의 결측치 표기를 통해 표시함
1. Nan
2. None

## 결측치 처리

### 제거
- `dropna()`: 결측치 데이터를 삭제, 경우에 따라 샘플이 많이 삭제될 수 있음 
    - `axis 0/1`: 0은 행 기준, 1은 열 기준으로 결측치를 삭제
    - `how = "all"`: 완전히 누락된 데이터만 삭제 
    - `thresh=n`: axis 값을 기준으로 정상적인 값이 n개 이상일 시 삭제하지 않음 
    - 

### 대체
> 분석자가 주관적으로 수행하는 것으로, 대체할 값에 대한 정답은 없음 

- `fillna()`: 특정 값 등으로 결측치 대체
    - 평균, 중위수, 최빈값
    - 유사한 데이터를 보고 추정을 통해 대체 
    - 존재하는 값들을 대상으로 모델을 만들어 예측

```python
data.fillna(mean) # 평균값으로 결측치 대체 
data.fillna({0:0, 1:99}) # 컬럼별로 결측치 대체
``` 

---

# 피벗테이블 
> 수집된 데이터를 원하는 항목/속성/기준으로 확인하고자 하는 것 

- 형식: `pd.pivot_table(데이터, index=[가로값], values=[세로값])`
    > 값을 채우는 방식을 지정하지 않면 평균으로 채움 

- 파라미터:
    - columns=["컬럼명"]: value를 항복별로 쪼개서 세부적인 내용 확인 
    - aggfunc=["집계함수"]: 값에 대한 집계 방법
    - fill_value=값: 결측값을 채움 
    - margins = T/F : True시 부분합(총계)을 계산 

## group by 와 차이점
> 기능적으로는 같고 (집계처리 등) 사용자가 익숙한 프로그램에서 사용되는 방식을 선택

- pivot_table: 엑셀사용자를 위한 기능, 결과를 데이터프레임 타입으로로 반환하므로 결과가 무거움, 판을 짜서 접근하는 형식  (xml/html)
- groupby: sql 에서 파생된 기능으로, 사용에 따라 결과를 시리즈로 반환하기도 하므로 데이터가 가벼움, 항목별로 묶어가면서 순차적으로 접근하는 형식

# groupby
> 데이터를 원하는 특성대로 하나씩 묶어서 확인하는 기능으로, 어떤 기준 묶어서 어떤 항목을 어떻게 집계 처리해서 볼 것인지가 핵심심

## 형식 
- SQL의 groupby구조

    ```sql
    select avg from grade group by class; /*개별 학생의 성적의 평균을 반 별로 묶어서 확인*/
    ```

- Pandas의 groupby구조: `df.groupby(by="묶을 항목")["필터링할 컬럼"].agg("집계함수")`

    ```python
    df.groupby(by="month")["duration"].mean() # month별로 묶은 데이터의 duration의 평균을 계산

    df.groupby(by=["month", "item"]) # 묶을 항목 복수 지정 

    df.groupby(by=["month", "item"]).agg(
        {
            "date": "first",
            "duration": "sum"
        }
    ) # 확인하고 싶은 각 항목별로 다르게 집계처리
    ```
   
    ### 옵션
    1. .groupby()`.head()/tail()`: 각 값으로 묶은 그룹의 처음 5개 값들만 반환
    2. `.groups.keys()` : 특정 항목으로 묶고 각 그룹의 고유값을 반환 
    3. `.agg("집계함수")`: 집계함수를 지정 (agg생략가능)
        - mean, sum, count 등
        - {"컬럼1":"집계1", "컬럼2":"집계2"}: 파라미터로 딕셔너리를 활용해 각 컬럼별로 집계를 다르게 적용해서 확인할 수 있음 
        ![결과](image.png)